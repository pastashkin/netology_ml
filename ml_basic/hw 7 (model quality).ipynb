{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание \"Методы оптимизации\"\n",
    "Преподаватель: Алексей Кузьмин\n",
    "1. Прочитать про методы оптимизации для нейронных сетей https://habr.com/post/318970/\n",
    "2. Реализовать самостоятельно логистическую регрессию\n",
    "3. Обучить ее методом:\n",
    "    - градиентного спуска\n",
    "    - nesterov momentum\n",
    "    - rmsprop\n",
    "4. В качестве dataset’а взять Iris, оставив 2 класса:\n",
    "    - Iris Versicolor\n",
    "    - Iris Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X = iris.data[iris.target != 0]\n",
    "y = iris.target[iris.target != 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Шкалируем X, переводим классы целевой переменной в бинарные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare our data\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y[y==2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напишем простую лог-регрессию, обучающуюся методом градиентного спуска.\n",
    "\n",
    "Обернем все это в класс с привычными методами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg_Gradient(object):\n",
    "    \n",
    "    def __init__(self, epochs=100, learning_rate=0.0001):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # fitting new params\n",
    "        if len(kwargs) !=0:\n",
    "            try:\n",
    "                if len(kwargs['epochs']) !=0:\n",
    "                    self.epochs = kwargs['epochs']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                if len(kwargs['learning_rate']) !=0:\n",
    "                    self.learning_rate = kwargs['learning_rate']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # set random params\n",
    "        params = np.random.normal(size=len(X[0])+1)\n",
    "        for _ in range(self.epochs):\n",
    "            # make predictions\n",
    "            pred = []\n",
    "            for each in X:\n",
    "                pred.append(1* params[0] +\n",
    "                            each[0] * params[1] +\n",
    "                            each[1] * params[2] + \n",
    "                            each[2] * params[3] + \n",
    "                            each[3] * params[4])\n",
    "\n",
    "            # y predicted\n",
    "            y_pred = []  \n",
    "            for each in pred:\n",
    "                y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "\n",
    "            # updating params\n",
    "            for param in range(len(params)):\n",
    "                new_param = []\n",
    "                for i in range(len(X)):\n",
    "                    if param == 0:\n",
    "                        new_param.append(1 * (y[i] - y_pred[i]))\n",
    "                    else:\n",
    "                        new_param.append(X[i][param-1] * (y[i] - y_pred[i]))\n",
    "                new_param = np.sum(new_param)\n",
    "                params[param] = params[param] + self.learning_rate * new_param\n",
    "            self.params = params\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred = []  \n",
    "        for each in pred:\n",
    "            y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "        return y_pred\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred_proba = []  \n",
    "        for each in pred:\n",
    "            y_pred_proba.append([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))])\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {'epochs': self.epochs,\n",
    "                'learning_rate': self.learning_rate}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим, что получилось..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_gradient = LogReg_Gradient(epochs=1500, learning_rate=0.0001)\n",
    "logreg_gradient.fit(X, y)\n",
    "accuracy_score(y, logreg_gradient.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ничего себе, получилось:)\n",
    "\n",
    "Проверим качество на кросс валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: \t [0.92 0.96 1.   1.  ]\n",
      "Mean accuracy: \t 0.97\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(logreg_gradient, X, y, fit_params={'epochs':1500, 'learning_rate': 0.0001}, scoring='accuracy', cv=4)\n",
    "print('CV scores: \\t', cv_scores)\n",
    "print('Mean accuracy: \\t', round(cv_scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Неплохие результаты, учитывая размера датасета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Напишем еще один класс, но уже для Nesterov Accelerated Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg_Nesterov(object):\n",
    "    \n",
    "    def __init__(self, epochs=100, learning_rate=0.0001, momentum=0.9):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum\n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # fitting new params\n",
    "        if len(kwargs) !=0:\n",
    "            try:\n",
    "                if len(kwargs['epochs']) !=0:\n",
    "                    self.epochs = kwargs['epochs']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                if len(kwargs['learning_rate']) !=0:\n",
    "                    self.learning_rate = kwargs['learning_rate']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                if len(kwargs['momentum']) !=0:\n",
    "                    self.momentum = kwargs['momentum']\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # set random params\n",
    "        params = np.random.normal(size=len(X[0])+1)\n",
    "        for _ in range(self.epochs):\n",
    "            # make predictions\n",
    "            pred = []\n",
    "            for each in X:\n",
    "                pred.append(1* params[0] +\n",
    "                            each[0] * params[1] +\n",
    "                            each[1] * params[2] + \n",
    "                            each[2] * params[3] + \n",
    "                            each[3] * params[4])\n",
    "\n",
    "            # y predicted\n",
    "            y_pred = []  \n",
    "            for each in pred:\n",
    "                y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "\n",
    "            # updating params\n",
    "            for param in range(len(params)):\n",
    "                new_param = []\n",
    "                old_param = 0\n",
    "                for i in range(len(X)):\n",
    "                    if param == 0:\n",
    "                        new_param.append(1 * (y[i] - y_pred[i]))\n",
    "                    else:\n",
    "                        new_param.append(X[i][param-1] * (y[i] - y_pred[i]))\n",
    "                new_param = np.sum(new_param)\n",
    "                params[param] = params[param] - self.momentum * old_param + self.learning_rate * new_param\n",
    "                old_param = new_param\n",
    "            self.params = params\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred = []  \n",
    "        for each in pred:\n",
    "            y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "        return y_pred\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred_proba = []  \n",
    "        for each in pred:\n",
    "            y_pred_proba.append([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))])\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {'epochs': self.epochs,\n",
    "                'learning_rate': self.learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_nesterov = LogReg_Nesterov(epochs=1500, momentum=0.9)\n",
    "logreg_nesterov.fit(X, y)\n",
    "accuracy_score(y, logreg_nesterov.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: \t [0.96 0.96 0.88 0.72]\n",
      "Mean accuracy: \t 0.88\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(logreg_nesterov, X, y, fit_params={'epochs':2000, 'learning_rate': 0.00005, 'momentum': 0.9}, scoring='accuracy', cv=4)\n",
    "print('CV scores: \\t', cv_scores)\n",
    "print('Mean accuracy: \\t', round(cv_scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже неплохо, результат лучше, чем с простым градиентом. Пришлось снижать параметр скорости обучения, т.к. инерция спуска иногда вызывала \"дребезжание\" в точке минимума."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Настало время опробовать rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogReg_rmsprop(object):\n",
    "    \n",
    "    def __init__(self, epochs=100, learning_rate=0.0001, momentum=0.9):\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.momentum = momentum   \n",
    "    \n",
    "    def fit(self, X, y, **kwargs):\n",
    "        # fitting new params\n",
    "        if len(kwargs) !=0:\n",
    "            try:\n",
    "                if len(kwargs['epochs']) !=0:\n",
    "                    self.epochs = kwargs['epochs']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                if len(kwargs['learning_rate']) !=0:\n",
    "                    self.learning_rate = kwargs['learning_rate']\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                if len(kwargs['momentum']) !=0:\n",
    "                    self.momentum = kwargs['momentum']\n",
    "            except:\n",
    "                pass\n",
    "       \n",
    "        # set random params\n",
    "        params = np.random.normal(size=len(X[0])+1)\n",
    "        for _ in range(self.epochs):\n",
    "            # make predictions\n",
    "            pred = []\n",
    "            for each in X:\n",
    "                pred.append(1* params[0] +\n",
    "                            each[0] * params[1] +\n",
    "                            each[1] * params[2] + \n",
    "                            each[2] * params[3] + \n",
    "                            each[3] * params[4])\n",
    "\n",
    "            # y predicted\n",
    "            y_pred = []  \n",
    "            for each in pred:\n",
    "                y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "\n",
    "            # updating params\n",
    "            for param in range(len(params)):\n",
    "                new_param = []\n",
    "                old_param = 0\n",
    "                for i in range(len(X)):\n",
    "                    if param == 0:\n",
    "                        new_param.append(1 * (y[i] - y_pred[i]))\n",
    "                    else:\n",
    "                        new_param.append(X[i][param-1] * (y[i] - y_pred[i]))\n",
    "                new_param = np.sum(new_param)\n",
    "                new_param = self.momentum * old_param + (1 - self.momentum) * new_param**2\n",
    "                params[param] = params[param] - self.learning_rate / (new_param**0.5 + 0.1) * new_param\n",
    "                old_param = new_param\n",
    "            self.params = params\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred = []  \n",
    "        for each in pred:\n",
    "            y_pred.append(np.argmax([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))]))\n",
    "        return y_pred\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pred = []\n",
    "        for each in X:\n",
    "            pred.append(1 * self.params[0] +\n",
    "                        each[0] * self.params[1] +\n",
    "                        each[1] * self.params[2] + \n",
    "                        each[2] * self.params[3] + \n",
    "                        each[3] * self.params[4])\n",
    "\n",
    "        # y predicted\n",
    "        y_pred_proba = []  \n",
    "        for each in pred:\n",
    "            y_pred_proba.append([(1 - 1/(1+np.e**-each)), (1/(1+np.e**-each))])\n",
    "        return y_pred_proba\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {'epochs': self.epochs,\n",
    "                'learning_rate': self.learning_rate}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_rmsprop = LogReg_rmsprop(epochs=1000, momentum=0.5, learning_rate=0.001)\n",
    "logreg_rmsprop.fit(X, y)\n",
    "accuracy_score(y, logreg_rmsprop.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV scores: \t [1.   0.84 0.92 0.96]\n",
      "Mean accuracy: \t 0.93\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(logreg_rmsprop, X, y, fit_params={'epochs':2000, 'learning_rate': 0.001, 'momentum': 0.7}, scoring='accuracy', cv=4)\n",
    "print('CV scores: \\t', cv_scores)\n",
    "print('Mean accuracy: \\t', round(cv_scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интересные результаты:\n",
    "- создается впечатление, что этот алгоритм намного быстрее предыдущих, т.к. за меньшее число эпох мне удавалось получать схожие с предыдущими результаты.\n",
    "- также можно задавать больший шаг"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
