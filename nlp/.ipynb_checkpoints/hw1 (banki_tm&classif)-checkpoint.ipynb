{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import bz2\n",
    "import regex\n",
    "from tqdm import tqdm\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201030it [02:13, 1503.24it/s]\n"
     ]
    }
   ],
   "source": [
    "responses = []\n",
    "with bz2.BZ2File('banki_responses.json.bz2', 'r') as thefile:\n",
    "    for row in tqdm(thefile):\n",
    "        resp = json.loads(row)\n",
    "        if not resp['rating_not_checked'] and (len(resp['text'].split()) > 0):\n",
    "            responses.append(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Домашнее задание по NLP # 1 [100 баллов]\n",
    "## Классификация по тональности \n",
    "\n",
    "В этом домашнем задании вам предстоит классифицировать по тональности отзывы на банки с сайта banki.ru.\n",
    "\n",
    "Данные содержат непосредственно тексты отзывов, некоторую дополнительную информацию, а также оценку по шкале от 1 до 5. \n",
    "\n",
    "Тексты хранятся в json-ах в массиве responses.\n",
    "\n",
    "Посмотрим на пример отзыва:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'author': 'ronnichka',\n",
       " 'bank_license': 'лицензия № 880',\n",
       " 'bank_name': 'Югра',\n",
       " 'city': 'г. Саратов',\n",
       " 'datetime': '2015-06-03 20:56:57',\n",
       " 'num_comments': 0,\n",
       " 'rating_grade': 3,\n",
       " 'rating_not_checked': False,\n",
       " 'text': 'Здравствуйте! Хотела написать, что мне месяц не выдают карту ко вкладу, ссылаясь на \"нам же их из Самары везут\" (на секундочку 5 часов езды от нашего города). Но! Прочитала, что людям 3,5 месяцев не выдают карту, и поняла, что у меня все хорошо, пока что. И подарок мне дали, и кулер в отделении есть. Так что я, конечно, готова ждать. Правда хотелось бы не очень долго.',\n",
       " 'title': 'Карта ко вкладу'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "responses[99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1. Анализ текстов [40/100]\n",
    "\n",
    "1. Посчитайте количество отзывов в разных городах и на разные банки\n",
    "2. Постройте гистограмы длин слов в символах и в словах\n",
    "3. Найдите 10 самых частых:\n",
    "    * слов\n",
    "    * слов без стоп-слов\n",
    "    * лемм \n",
    "* существительных\n",
    "4. Постройте кривые Ципфа и Хипса\n",
    "5. Ответьте на следующие вопросы:\n",
    "    * какое слово встречается чаще, \"сотрудник\" или \"клиент\"?\n",
    "    * сколько раз встречается слова \"мошенничество\" и \"доверие\"?\n",
    "6. В поле \"rating_grade\" записана оценка отзыва по шкале от 1 до 5. Используйте меру $tf-idf$, для того, чтобы найти ключевые слова и биграмы для положительных отзывов (с оценкой 5) и отрицательных отзывов (с оценкой 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2. Тематическое моделирование [20/100]\n",
    "\n",
    "1. Постройте несколько тематических моделей коллекции документов с разным числом тем. Приведите примеры понятных (интерпретируемых) тем.\n",
    "2. Найдите темы, в которых упомянуты конкретные банки (Сбербанк, ВТБ, другой банк). Можете ли вы их прокомментировать / объяснить?\n",
    "\n",
    "Эта часть задания может быть сделана с использованием gensim. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3. Классификация текстов [40/100]\n",
    "\n",
    "Сформулируем для простоты задачу бинарной классификации: будем классифицировать на два класса, то есть, различать резко отрицательные отзывы (с оценкой 1) и положительные отзывы (с оценкой 5). \n",
    "\n",
    "1.  Составьте обучающее и тестовое множество: выберите из всего набора данных N1 отзывов с оценкой 1 и N2 отзывов с оценкой 5 (значение N1 и N2 – на ваше усмотрение). Используйте ```sklearn.model_selection.train_test_split``` для разделения множества отобранных документов на обучающее и тестовое. \n",
    "2. Используйте любой известный вам алгоритм классификации текстов для решения задачи и получите baseline. Сравните разные варианты векторизации текста: использование только униграм, пар или троек слов или с использованием символьных $n$-грам. \n",
    "3. Сравните, как изменяется качество решения задачи при использовании скрытых тем в качестве признаков:\n",
    "* 1-ый вариант: $tf-idf$ преобразование (```sklearn.feature_extraction.text.TfidfTransformer```) и сингулярное разложение (оно же – латентый семантический анализ) (```sklearn.decomposition.TruncatedSVD```), \n",
    "* 2-ой вариант: тематические модели LDA (```sklearn.decomposition.LatentDirichletAllocation```). \n",
    "\n",
    "Используйте accuracy и F-measure для оценки качества классификации. \n",
    "\n",
    "Ниже написан примерный Pipeline для классификации текстов. \n",
    "\n",
    "Эта часть задания может быть сделана с использованием sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-77be54944135>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m clf = Pipeline([ \n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'vect'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'tfidf'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTfidfTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'tm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTruncatedSVD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# !!! На каждом этапе Pipeline нужно указать свои параметры\n",
    "# 1-ый вариант: tf-idf + LSI\n",
    "# 2-ой вариант: LDA\n",
    "\n",
    "# clf = Pipeline([\n",
    "#     ('vect', CountVectorizer(analyzer = 'char', ngram_range={4,6})),\n",
    "#     ('clf', RandomForestClassifier()),\n",
    "# ])\n",
    "\n",
    "\n",
    "\n",
    "clf = Pipeline([ \n",
    "    ('vect', CountVectorizer()), \n",
    "    ('tfidf', TfidfTransformer()), \n",
    "    ('tm', TruncatedSVD()), \n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
